{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilal Shehata and Armaan Mcleoud \n",
    "--DREAM TEAM--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL TO LOAD IN FUNCTIONS\n",
    "\n",
    "#imports used for program\n",
    "\n",
    "import itertools\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "\n",
    "def k_fold(fulldf):\n",
    "    #split array into 10 pieces\n",
    "    karrays = np.array_split(fulldf,K)\n",
    "  \n",
    "    counter = 0 \n",
    "    sum = 0 #record results\n",
    "    \n",
    "    for i in range(0,len(karrays)):\n",
    "        counter = 0\n",
    "        testdf = karrays[i] #set the test array as one of the chunks\n",
    "        \n",
    "       \n",
    "        for j in range(0,len(karrays)):\n",
    "            #ensure that were not adding the test chunk to the array \n",
    "            if i != j: \n",
    "                \n",
    "               if counter == 0:\n",
    "                   counter+=1\n",
    "                   traindf = karrays[j] #initialise the data to be trained\n",
    "                   continue \n",
    "               #concatinate all the chunks that arent the test chunk\n",
    "               traindf = pd.concat([traindf,karrays[j]],axis = 0) \n",
    "        \n",
    "        #train the classifer by building the probability dictionary \n",
    "        probs, classes, priors = train_supervised(traindf)\n",
    "        #evaluate the classifier \n",
    "    \n",
    "        sum+= evaluate_supervised(testdf, probs, classes,priors)\n",
    "        \n",
    "    return sum/K       \n",
    "\n",
    "def deterministic_preprocess():\n",
    "     df = pd.read_csv(filepath, header = None)\n",
    "      \n",
    "     clean(df) #impute missing values if they exist\n",
    "     df = df.sample(frac=1).reset_index(drop=True) #shuffles the dataframe\n",
    "     classes = df[len(df.columns)-1].unique()\n",
    "      \n",
    "     df = df.iloc[:, :-1]\n",
    "    \n",
    "    \n",
    "  \n",
    "     df[len(df.columns)-1] = np.random.choice(classes, df.shape[0])\n",
    "     \n",
    "    \n",
    "   \n",
    "   \n",
    "     return df, classes\n",
    "def preprocess():\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(filepath, header = None)\n",
    "\n",
    "    clean(df) #impute missing values if they exist\n",
    "    df = df.sample(frac=1).reset_index(drop=True) #shuffles the dataframe\n",
    "  \n",
    "    \n",
    "    return df\n",
    "\n",
    "               \n",
    "           \n",
    "def train_supervised(df):\n",
    "    \n",
    "    #prior probabilties\n",
    "    highProb = df.groupby(len(df.columns)-1).size().div(len(df))\n",
    "     \n",
    "    #probabiltiy deictionary \n",
    "    probList = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    #this loop calculates the probabilties \n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        cols =[len(df.columns)-1,i]\n",
    "       \n",
    "        trained = df.groupby(cols).size().div(len(df)).multiply(highProb, axis = 0,level=(len(df.columns)-1))\n",
    "        \n",
    "        probList[i] = trained\n",
    "    \n",
    "    #converts dataframe into dictionary \n",
    "    for i in range(0,len(probList)):\n",
    "        probList[i] = probList[i].to_dict()\n",
    "        #collects the classes into an list\n",
    "    classes = df[len(df.columns)-1].unique()\n",
    "    \n",
    "    priors = get_super_priors(df,classes)\n",
    "    \n",
    "    return probList, classes, priors\n",
    "\n",
    "def evaluate_supervised(testcsv, probs,classes,priors):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    #iterate over each of the rows and pass it to the predict supervised method\n",
    "    for index, testrow in testcsv.iterrows() :\n",
    "        \n",
    "        \n",
    "        if predict_supervised(probs, testrow.tolist(),classes,priors) == testrow[len(testcsv.columns)-1]:\n",
    "            \n",
    "            correct +=1\n",
    "     \n",
    "        total +=1\n",
    "        \n",
    "     \n",
    "    return correct/total\n",
    "            \n",
    "#cleaning methiod removes '?' and places in it the most common value for that column\n",
    "def clean(dataframe):\n",
    "    for index, testrow in dataframe.iterrows():\n",
    "      for i in range(0,len(testrow)):\n",
    "          if testrow[i] == '?':\n",
    "              testrow[i] = dataframe[i].value_counts().idxmax()\n",
    "  \n",
    "    return dataframe\n",
    "     \n",
    "\n",
    "    \n",
    "    #train the data\n",
    "  \n",
    "\n",
    "#function is used for preprocessing the data for unsupervised method \n",
    "def unsupervised_preprocess():\n",
    "      df = pd.read_csv(filepath, header = None)\n",
    "      \n",
    "      df = clean(df) #impute missing values if they exist\n",
    "      df = df.sample(frac=1).reset_index(drop=True) #shuffles the dataframe\n",
    "      classes = sorted(df[len(df.columns)-1].unique()) #returns the set of classes from dataframe\n",
    "   \n",
    "      df = df.iloc[:, :-1] #for unsupervised method the classes are cropped off the dataframe \n",
    "      #for each row and class assign a random value to the classes\n",
    "      for probable_class in classes:\n",
    "          df[probable_class] = pd.Series(np.random.rand(len(df)))\n",
    "      #ensure that the values are normalised\n",
    "      normalise_unsupervised(df,classes)\n",
    "      \n",
    "   \n",
    "      return df, classes\n",
    "#function is used to normalise the distributions of the pandas file in the dataframe     \n",
    "def normalise_unsupervised(df, classes):\n",
    "    #iterate through the rows\n",
    "    for index, row in df.iterrows():\n",
    "        #iterate through the attributes which are classes\n",
    "        total = sum(row[-len(classes):])\n",
    "        for i in range((len(row)-len(classes)),len(row)):\n",
    "            temp= float(row[i])/total\n",
    "            df.loc[index,df.columns[i] ] = temp\n",
    "      \n",
    "   \n",
    "    return\n",
    "\n",
    "#function to return the prior probablities in the supervised method\n",
    "def get_super_priors(df,classes):\n",
    "    priors = [0.0] * len(classes)\n",
    "    total = 0\n",
    "    classes = classes.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        priors[classes.index(row[len(row)-1])] += 1 \n",
    "        total += 1\n",
    "    for i in range(len(priors)):\n",
    "        priors[i] = priors[i]/total\n",
    "\n",
    "           \n",
    "      \n",
    "   \n",
    "    return priors\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised(df, classes):\n",
    "   \n",
    "\n",
    "    priors= get_priors(df,classes)\n",
    "    \n",
    "    iterations = 4\n",
    "    for i in range(1,iterations): \n",
    "       \n",
    "        probList = make_probability_dictionary(df,classes)\n",
    "        probList = factional_divide(df,classes,probList)\n",
    "\n",
    "        df = assign_distro(df,classes,probList,priors)\n",
    "\n",
    "    \n",
    "    return probList, classes, priors\n",
    "\n",
    "def factional_divide(df,classes,probList):\n",
    "    fraccounts = get_fraccounts(df,classes)\n",
    "    for i in probList.keys():\n",
    "        for classtype in probList[i].keys():\n",
    "            for value in probList[i][classtype].keys():\n",
    "                \n",
    "                    probList[i][classtype][value] = probList[i][classtype][value] / fraccounts[classes.index(classtype)]\n",
    "\n",
    "    return probList\n",
    "\n",
    "\n",
    "def get_fraccounts(df,classes):\n",
    "    fraccounts = []\n",
    "    for i in classes:   \n",
    "        fraccounts.append(sum(df[i]))\n",
    "    \n",
    "    return fraccounts\n",
    "\n",
    "def make_probability_dictionary(df,classes):\n",
    "     probList = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda:0.00000001)))\n",
    "     for prob_class in range(0,len(classes)):\n",
    "        for index, row in df.iterrows() :\n",
    "            for i in range(0,len(row)-len(classes)):\n",
    "                probList[i][classes[prob_class]][row[i]] +=row[len(row)-len(classes)+prob_class]\n",
    "     return probList\n",
    "    \n",
    "def assign_distro(df,classes,probList,classProbs):\n",
    "     for index, row in df.iterrows():\n",
    "       \n",
    "       \n",
    "       for probable_Class in range(len(classes)):\n",
    "        \n",
    "           product = 1 * classProbs[probable_Class]\n",
    "           \n",
    "           for attrib in range((len(row)-len(classes))):    \n",
    "              \n",
    "               product = product *probList[attrib][classes[probable_Class]][row[attrib]]\n",
    "               \n",
    "           df.loc[index,df.columns[(len(row)-len(classes) + probable_Class)]] = product\n",
    "    \n",
    "     normalise_unsupervised(df,classes)\n",
    "     \n",
    "     return df\n",
    "    \n",
    "def get_priors(df,classes):\n",
    "    classProbs = []\n",
    "    for i in classes:   \n",
    "        classProbs.append(sum(df[i])/len(df))\n",
    "    \n",
    "    return classProbs\n",
    "\n",
    "def predict_supervised(probList,testrow,classes,priors):\n",
    "    \n",
    "    classChance = [0.0] * len(classes)#keep record of all classchanes for this row\n",
    "    classlist = classes.tolist()\n",
    "    for possibleClass in classes : \n",
    "        \n",
    "        prob =1 *priors[classlist.index(possibleClass)]\n",
    "        for i in range(0,len(testrow)-1) : #for every element multiply in \n",
    "  \n",
    "            if (possibleClass,testrow[i]) in probList[i]: \n",
    "                \n",
    "                prob = prob * probList[i][(possibleClass,testrow[i])]\n",
    "            else : \n",
    "               \n",
    "                prob = prob * 0.00000000000001 #epsilon \n",
    "        classChance[classlist.index(possibleClass)]= prob\n",
    "        \n",
    "        \n",
    "\n",
    "            #here we get the highest probability and match it to the class\n",
    "    \n",
    "\n",
    "    return classes[classChance.index(max(classChance))]\n",
    "\n",
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised(probList,testrow,classes,priors):\n",
    "        \n",
    "    shuffle(classes)\n",
    "    classChance = [0.0] * len(classes)#keep record of all classchanes for this row\n",
    "    classlist = classes\n",
    "    for possibleClass in classes : \n",
    "        \n",
    "        prob =1 *priors[classlist.index(possibleClass)]\n",
    "        for i in range(0,len(testrow)-len(classes)) : #for every element multiply in \n",
    "  \n",
    "            if testrow[i] in probList[i][possibleClass]: \n",
    "              \n",
    "                prob = prob * probList[i][possibleClass][testrow[i]]\n",
    "            else: \n",
    "               \n",
    "               prob = prob * 0.0000000001 #epsilon \n",
    "        classChance[classlist.index(possibleClass)]= prob\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    return classes[classChance.index(max(classChance))]\n",
    "  \n",
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "'''def evaluate_unsupervised(testcsv, probs,classes,priors):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0 \n",
    "\n",
    "    #iterate over each of the rows and pass it to the predict supervised method\n",
    "    for index, testrow in testcsv.iterrows() :\n",
    "        \n",
    "            \n",
    "        \n",
    "        if predict_unsupervised(probs, testrow.tolist(),classes,priors) == testrow[len(testcsv.columns)-1]:\n",
    "            \n",
    "            correct +=1\n",
    "\n",
    "        total +=1\n",
    "        \n",
    "     \n",
    "    return correct/total'''\n",
    "def evaluate_unsupervised(testcsv, probs, classes,priors):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    guesses = list()\n",
    "    trues = list()\n",
    "    #iterate over each of the rows and pass it to the predict supervised method\n",
    "    for index, testrow in testcsv.iterrows() :\n",
    "        \n",
    "            \n",
    "        \n",
    "        if predict_unsupervised(probs, testrow.tolist(),classes,priors) == testrow[len(testcsv.columns)-1]:\n",
    "            \n",
    "            correct +=1\n",
    "        guesses.append(predict_unsupervised(probs, testrow.tolist(),classes,priors))\n",
    "        trues.append(testrow[len(testcsv.columns)-1])\n",
    "        \n",
    "        total +=1\n",
    "    #this section generates a confusion matrix \n",
    "    cm = confusion_matrix(trues, guesses, labels=classes)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm,cmap= plt.cm.Greens)\n",
    "  \n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    width, height = cm.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate('%.4f' % cm[x][y], xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    print(correct/total)\n",
    "\n",
    "        \n",
    "\n",
    "    return  confusion_matrix(trues, guesses)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: \n",
    "\n",
    "The unsuperivsed niave bayes (NB) has no concept of \"classes\" and therefore the classes can sometime end up \"swapped\" therefore reducing the overall accuracy for that unsupervised NB instance. Another factor which effects the the accuracy of the classifier is the proportion of nominal attributes compared to the number of instances. The reason why the unsupervised NB works at all is because we initially generated non-uniform data which is similar to the non-uniform data provided. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392417528311177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3569,  639],\n",
       "       [ 669, 3247]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"./datasets/mushroom-dos.csv\"\n",
    "\n",
    "#driver made to preprocess train and evaluate an unsupervised classifier\n",
    "def unsuper_driver():\n",
    "    unsuper_df, classes = unsupervised_preprocess()\n",
    "    probList, classes, priors = train_unsupervised(unsuper_df, classes)\n",
    "    testdf = pd.read_csv(filepath, header = None)\n",
    "   \n",
    "\n",
    "    return evaluate_unsupervised(testdf,probList,classes,priors)\n",
    "unsuper_driver()\n",
    "\n",
    "#print(str(unsuper_driver()*100)+'%' + \" Accuracy for unsupervised algorithm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "The performance of the supervised classifier tends to work better with more instances (rows) in the dataset. This however is not the case between \"breast-cancer\" and \"cars\" datasets, however this variation could be due to cars having a higher number of classes which causes its accuracy to be lower despite having more instances overall. \n",
    "\n",
    "furthermore another accuracy influence could be due to the higher number of nominal attributes allows the classifier to be more accurate. This could be explained by the classifiers ability to be more specific due to the higher number of attributes. For example the chance of a combination of 22 attributes occuring twice in the same dataset is low, therefore the classifier will most likely recognise the class of the instance with those attributes if it needs to predict it since there will be few other options that match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.22605121719886% Accuracy for supervised algorithm\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./datasets/hypothyroid-dos.csv\"\n",
    "#driver made to preprocess train and evaluate a  supervised\n",
    "def simple_driver():\n",
    "\n",
    "    df = pd.read_csv(filepath, header = None)\n",
    "  \n",
    "    probs, classes, priors = train_supervised(df)\n",
    "    \n",
    "    return evaluate_supervised(df, probs,classes,priors)\n",
    "print(str(simple_driver()*100)+'%' + \" Accuracy for supervised algorithm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "The accuracy of testing using k-fold cross-validation method was quite close to the accuracy of testing on training data. As the number of K increases the accuracy converges with that of Training on test data. However the processing time also increases exponentially and therefore there is a tradeoff between accuracy rating and CPU time. This is most prominent when using the \"Hold one\" method where K is the datasets size less 1. Where the accuracies are equal however the training time is unfeasible for lager datasets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.02184433391584% Accuracy for supervised algorithm using k-fold cross validation\n",
      "70.02314814814815% Accuracy for supervised algorithm without using cross validation\n",
      "quite close in accuracy\n"
     ]
    }
   ],
   "source": [
    "K  = 10 # k is the number of pieces to divide the data into must be atleast 2\n",
    "\n",
    "filepath = \"./datasets/car-dos.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def driver():\n",
    "    fulldf = preprocess()\n",
    "    \n",
    "    return k_fold(fulldf)\n",
    "print(str(driver()*100)+'%' + \" Accuracy for supervised algorithm using k-fold cross validation\")\n",
    "    \n",
    "    \n",
    "def non_kfold_driver():\n",
    "\n",
    "    df = pd.read_csv(filepath, header = None)\n",
    "  \n",
    "    probs, classes,priors = train_supervised(df)\n",
    "    \n",
    "    return evaluate_supervised(df, probs,classes,priors)\n",
    "print(str(non_kfold_driver()*100)+'%' + \" Accuracy for supervised algorithm without using cross validation\")\n",
    "\n",
    "print(\"quite close in accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "\n",
    "By deterministically assigning a random class to each instance. The accuracy will converge to 1/classes as instances increase. In contrast, if you instead assign a non-uniform distribution to each instance, through iterations the data's distrubution will become closer to the distrubution of the original dataset and therefore has potential to be much higher accuracy than the deterministic approach that is 1/classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.96427442301612% Accuracy for unsupervised deterministic algorithm without using cross validation\n",
      "26.15740740740741% Accuracy for unsupervised deterministic algorithm without using cross validation\n",
      "54.89510489510489% Accuracy for unsupervised deterministic algorithm without using cross validation\n",
      "^^ trend can be identified as 1/classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = \"./datasets/hypothyroid-dos.csv\"\n",
    "\n",
    "def deterministic_driver():\n",
    "    df, classes = deterministic_preprocess()\n",
    "  \n",
    "    probs, classes,priors = train_supervised(df)\n",
    "    \n",
    "    return evaluate_supervised(df, probs,classes,priors)\n",
    "\n",
    "print(str(deterministic_driver()*100)+ \"%\" + \" Accuracy for unsupervised deterministic algorithm without using cross validation\")\n",
    "\n",
    "filepath = \"./datasets/car-dos.csv\"\n",
    "\n",
    "print(str(deterministic_driver()*100)+ \"%\" + \" Accuracy for unsupervised deterministic algorithm without using cross validation\")\n",
    "\n",
    "filepath = \"./datasets/breast-cancer-dos.csv\"\n",
    "\n",
    "print(str(deterministic_driver()*100)+ \"%\" + \" Accuracy for unsupervised deterministic algorithm without using cross validation\")\n",
    "\n",
    "print(\"^^ trend can be identified as 1/classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
